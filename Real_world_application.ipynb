{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751654b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import wfdb.processing\n",
    "from scipy.signal import butter, filtfilt\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2d8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Helper Functions & Constants (Copied from your project) ---\n",
    "\n",
    "# The \"Forward Map\" (Characters -> Integers)\n",
    "# Not strictly needed for *this* script's pipeline, but good to have\n",
    "AAMI_MAPPING = {\n",
    "    # Class N (Normal Beats -> 0)\n",
    "    'N': 0, 'L': 0, 'R': 0, 'e': 0, 'j': 0, '/': 0,\n",
    "    \n",
    "    # Class S (Supraventricular Ectopic Beats -> 1)\n",
    "    'A': 1, 'a': 1, 'J': 1, 'S': 1,\n",
    "    \n",
    "    # Class V (Ventricular Ectopic Beats -> 2)\n",
    "    'V': 2, 'E': 2,\n",
    "    \n",
    "    # Class F (Fusion Beats -> 3)\n",
    "    'F': 3, 'f': 3,\n",
    "    \n",
    "    # Class Q (Unclassifiable/Other Beats -> 4)\n",
    "    'Q': 4,\n",
    "    \n",
    "    # Non-Beat/Noise Annotations (To be filtered out -> -1)\n",
    "    '!': -1, '\"': -1, '+': -1, '[': -1, ']': -1,\n",
    "    '|': -1, 'x': -1, '~': -1\n",
    "}\n",
    "\n",
    "# The \"Reverse Map\" (Integers -> Strings)\n",
    "# This IS needed for the final report in Step 5\n",
    "AAMI_CLASS_NAMES = ['N (Normal)', 'S (Supraventricular)', 'V (Ventricular)', 'F (Fusion)', 'Q (Unclassifiable)']\n",
    "\n",
    "def bandpass_filter(segment, fs=360, lowcut=0.5, highcut=45, order=4):\n",
    "    \"\"\"Applies the bandpass filter.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, segment, axis=0)\n",
    "\n",
    "def global_zscore_normalize(segment, mean, std):\n",
    "    \"\"\"Normalizes a segment using the pre-calculated global mean and std.\"\"\"\n",
    "    return (segment - mean) / (std + 1e-8) # Add 1e-8 to prevent division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc06a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. CRITICAL: Set Your Preprocessing Stats ---\n",
    "\n",
    "GLOBAL_MEAN = np.array([ 0.02254995, -0.00905314]) \n",
    "GLOBAL_STD = np.array([ 0.41518577,  0.33936556])  \n",
    "\n",
    "\n",
    "# Path to your database\n",
    "DB_PATH = r\"C:\\Me\\College\\4th\\Ai_in_healthcare\\Ai_in_healthcare_project\\database\"\n",
    "\n",
    "RECORD_TO_ANALYZE = \"234\" \n",
    "RECORD_FILE = os.path.join(DB_PATH, RECORD_TO_ANALYZE)\n",
    "\n",
    "# Model configuration\n",
    "WINDOW_SIZE = 180\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cafd4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_full_record(record_path):\n",
    "\n",
    "    print(f\"--- Starting 5-Step Pipeline for Record: {RECORD_TO_ANALYZE} ---\")\n",
    "\n",
    "    # --- Step 1: Load the Raw Signal ---\n",
    "    print(f\"\\nStep 1: Loading raw signal from {record_path}...\")\n",
    "    try:\n",
    "        record = wfdb.rdrecord(record_path)\n",
    "        signal = record.p_signal\n",
    "        fs = record.fs\n",
    "        print(f\"Signal loaded successfully. Shape: {signal.shape}, Fs: {fs} Hz\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading record: {e}\")\n",
    "        return None, None # <-- MODIFIED: Return None on failure\n",
    "\n",
    "    # --- Step 2: Find All Heartbeats (QRS Detection) ---\n",
    "    print(f\"\\nStep 2: Finding all heartbeats (QRS detection)...\")\n",
    "    # We use the 'gqrs_detect' algorithm on the first channel (MLII)\n",
    "    qrs_indices = wfdb.processing.gqrs_detect(sig=signal[:, 0], fs=fs)\n",
    "    print(f\"Found {len(qrs_indices)} heartbeats (QRS peaks).\")\n",
    "\n",
    "    # --- Step 3: Create a \"Batch\" of All Segments ---\n",
    "    print(\"\\nStep 3: Extracting, filtering, and normalizing all segments...\")\n",
    "    patient_segments = []\n",
    "    \n",
    "    for sample_idx in qrs_indices:\n",
    "        # Check if the beat is too close to the edge\n",
    "        if sample_idx - WINDOW_SIZE//2 < 0 or sample_idx + WINDOW_SIZE//2 >= signal.shape[0]:\n",
    "            continue # Skip this beat\n",
    "\n",
    "        # Extract: (Window is 180 samples)\n",
    "        seg = signal[sample_idx - WINDOW_SIZE//2 : sample_idx + WINDOW_SIZE//2]\n",
    "        \n",
    "        # Filter:\n",
    "        filtered_seg = bandpass_filter(seg, fs=fs)\n",
    "        \n",
    "        # Normalize: (Using the GLOBAL stats)\n",
    "        normalized_seg = global_zscore_normalize(filtered_seg, GLOBAL_MEAN, GLOBAL_STD)\n",
    "        \n",
    "        # Append to our batch\n",
    "        patient_segments.append(normalized_seg)\n",
    "\n",
    "    # Stack all segments into a single NumPy array\n",
    "    X_new_patient = np.array(patient_segments)\n",
    "    \n",
    "    # --- FIX: Handle case where no valid segments were found ---\n",
    "    if X_new_patient.shape[0] == 0:\n",
    "        print(\"No valid segments could be extracted from the record.\")\n",
    "        return None, None # <-- MODIFIED: Return None on failure\n",
    "        \n",
    "    print(f\"Created batch of {X_new_patient.shape[0]} valid segments.\")\n",
    "# ... existing code ... # e.g., (2135, 180, 2)\n",
    "\n",
    "    # --- Step 4: Run Batch Prediction ---\n",
    "    print(\"\\nStep 4: Loading model and running batch prediction...\")\n",
    "    try:\n",
    "        model = tf.keras.models.load_model('optimal_ecg_model.keras')\n",
    "        print(\"Model 'optimal_ecg_model.keras' loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None, None # <-- MODIFIED: Return None on failure\n",
    "\n",
    "    # Predict on the entire batch at once (very fast)\n",
    "    all_predictions_proba = model.predict(X_new_patient)\n",
    "    \n",
    "    # Get Final Labels (e.g., [0, 0, 1, 0, 2, ...])\n",
    "    all_predicted_labels = np.argmax(all_predictions_proba, axis=1)\n",
    "    print(f\"Prediction complete. Got {len(all_predicted_labels)} labels.\")\n",
    "\n",
    "    # --- Step 5: Compute the Final Result (Aggregation) ---\n",
    "    print(\"\\nStep 5: Generating final arrhythmia report...\")\n",
    "    \n",
    "    label_counts = Counter(all_predicted_labels)\n",
    "    total_beats = len(all_predicted_labels)\n",
    "\n",
    "    # --- Build one single string for the report.\n",
    "    report_string = \"\"\n",
    "    report_string += \"\\n\" + \"=\"*40 + \"\\n\"\n",
    "    report_string += \"     MODEL PREDICTION REPORT\\n\"\n",
    "    report_string += f\"     Record: {RECORD_TO_ANALYZE}\\n\"\n",
    "    report_string += \"=\"*40 + \"\\n\"\n",
    "    report_string += f\"Total Beats Detected (by gqrs_detect): {total_beats}\\n\\n\"\n",
    "\n",
    "    if total_beats > 0:\n",
    "        # Class 0: N\n",
    "        count_n = label_counts.get(0, 0)\n",
    "        percent_n = (count_n / total_beats) * 100\n",
    "        report_string += f\"  {AAMI_CLASS_NAMES[0]:<25}: {count_n:<6} beats ({percent_n:.2f}%)\\n\"\n",
    "        \n",
    "        # Class 1: S\n",
    "        count_s = label_counts.get(1, 0)\n",
    "        percent_s = (count_s / total_beats) * 100\n",
    "        report_string += f\"  {AAMI_CLASS_NAMES[1]:<25}: {count_s:<6} beats ({percent_s:.2f}%)\\n\"\n",
    "        \n",
    "        # Class 2: V\n",
    "        count_v = label_counts.get(2, 0)\n",
    "        percent_v = (count_v / total_beats) * 100\n",
    "        report_string += f\"  {AAMI_CLASS_NAMES[2]:<25}: {count_v:<6} beats ({percent_v:.2f}%)\\n\"\n",
    "        \n",
    "        # Class 3: F\n",
    "        count_f = label_counts.get(3, 0)\n",
    "        percent_f = (count_f / total_beats) * 100\n",
    "        report_string += f\"  {AAMI_CLASS_NAMES[3]:<25}: {count_f:<6} beats ({percent_f:.2f}%)\\n\"\n",
    "        \n",
    "        # Class 4: Q\n",
    "        count_q = label_counts.get(4, 0)\n",
    "        percent_q = (count_q / total_beats) * 100\n",
    "        report_string += f\"  {AAMI_CLASS_NAMES[4]:<25}: {count_q:<6} beats ({percent_q:.2f}%)\"\n",
    "    else:\n",
    "        report_string = \"  No beats were analyzed.\"\n",
    "\n",
    "    report_string += \"\\n\" + \"=\"*40\n",
    "    \n",
    "    # Print the entire report string at once to the console\n",
    "    print(report_string, flush=True)\n",
    "\n",
    "    # --- Save the report to a text file ---\n",
    "    report_filename = f\"final_report_{RECORD_TO_ANALYZE}.txt\"\n",
    "    try:\n",
    "        with open(report_filename, \"w\") as f:\n",
    "            f.write(report_string)\n",
    "        print(f\"\\nSUCCESS: Full report also saved to {report_filename}\")\n",
    "        print(\"Please open this file to see the untruncated output.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWarning: Could not save report file. {e}\")\n",
    "        \n",
    "    # --- MODIFIED: Return the full list of labels for Step 6 ---\n",
    "    return all_predicted_labels, total_beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11750d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. NEW FUNCTION: Check Ground Truth ---\n",
    "def check_ground_truth(record_path):\n",
    "    \"\"\"\n",
    "    Loads the .atr file for a record, maps the symbols to AAMI classes,\n",
    "    and prints the \"ground truth\" counts for comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"     GENERATING GROUND TRUTH REPORT\")\n",
    "    print(f\"     Record: {RECORD_TO_ANALYZE}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    try:\n",
    "        # 1. Load the ground truth annotations\n",
    "        annotation = wfdb.rdann(record_path, 'atr')\n",
    "        raw_symbols = annotation.symbol\n",
    "        \n",
    "        # 2. Map symbols to AAMI integers (0-4)\n",
    "        # We must filter out the non-beat (-1) symbols\n",
    "        true_labels_int = []\n",
    "        for s in raw_symbols:\n",
    "            mapped_class = AAMI_MAPPING.get(s, -1) # Get class, default to -1\n",
    "            if mapped_class != -1: # Only include valid beats (0-4)\n",
    "                true_labels_int.append(mapped_class)\n",
    "\n",
    "        # 3. Count the mapped labels\n",
    "        label_counts = Counter(true_labels_int)\n",
    "        \n",
    "        # Get total counts\n",
    "        total_beats = len(true_labels_int) # This is the count *after* filtering non-beats\n",
    "        total_raw_annotations = len(raw_symbols) # This is the *total* count\n",
    "        \n",
    "        # --- 4. Build the report string (THIS IS THE FIX) ---\n",
    "        report_string = \"\"\n",
    "        report_string += \"\\n\" + \"=\"*40 + \"\\n\"\n",
    "        report_string += \"     GROUND TRUTH REPORT\\n\"\n",
    "        report_string += f\"     Record: {RECORD_TO_ANALYZE}\\n\"\n",
    "        report_string += \"=\"*40 + \"\\n\"\n",
    "        report_string += f\"Total Valid Beats (from .atr file): {total_beats}\\n\"\n",
    "        report_string += f\"(Total Raw Annotations in file: {total_raw_annotations})\\n\\n\"\n",
    "\n",
    "        if total_beats > 0:\n",
    "            count_n = label_counts.get(0, 0)\n",
    "            percent_n = (count_n / total_beats) * 100\n",
    "            report_string += f\"  {AAMI_CLASS_NAMES[0]:<25}: {count_n:<6} beats ({percent_n:.2f}%)\\n\"\n",
    "            \n",
    "            count_s = label_counts.get(1, 0)\n",
    "            percent_s = (count_s / total_beats) * 100\n",
    "            report_string += f\"  {AAMI_CLASS_NAMES[1]:<25}: {count_s:<6} beats ({percent_s:.2f}%)\\n\"\n",
    "            \n",
    "            count_v = label_counts.get(2, 0)\n",
    "            percent_v = (count_v / total_beats) * 100\n",
    "            report_string += f\"  {AAMI_CLASS_NAMES[2]:<25}: {count_v:<6} beats ({percent_v:.2f}%)\\n\"\n",
    "            \n",
    "            count_f = label_counts.get(3, 0)\n",
    "            percent_f = (count_f / total_beats) * 100\n",
    "            report_string += f\"  {AAMI_CLASS_NAMES[3]:<25}: {count_f:<6} beats ({percent_f:.2f}%)\\n\"\n",
    "            \n",
    "            count_q = label_counts.get(4, 0)\n",
    "            percent_q = (count_q / total_beats) * 100\n",
    "            report_string += f\"  {AAMI_CLASS_NAMES[4]:<25}: {count_q:<6} beats ({percent_q:.2f}%)\"\n",
    "        else:\n",
    "            report_string = \"  No valid beats found in .atr file.\"\n",
    "\n",
    "        report_string += \"\\n\" + \"=\"*40\n",
    "        \n",
    "        # --- MODIFICATION: Removed the console print() statement ---\n",
    "        \n",
    "        # --- Save the report to a text file ---\n",
    "        report_filename = f\"ground_truth_report_{RECORD_TO_ANALYZE}.txt\"\n",
    "        try:\n",
    "            with open(report_filename, \"w\") as f:\n",
    "                f.write(report_string)\n",
    "            print(f\"\\nSUCCESS: Ground truth report saved to {report_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Could not save report file. {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ground truth annotations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870f72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. \"SMARTER\" DIAGNOSTIC FUNCTION (THE FIX) ---\n",
    "def generate_diagnostic_report(all_predicted_labels, total_beats):\n",
    "    \"\"\"\n",
    "    Takes the *full list* of predicted labels (not just the counts)\n",
    "    and generates a smarter \"Yes/No\" diagnosis by looking for patterns\n",
    "    and clinical frequency thresholds.\n",
    "    \"\"\"\n",
    "    \n",
    "    report_string = \"\"\n",
    "    report_string += \"\\n\" + \"=\"*50 + \"\\n\"\n",
    "    report_string += \"     FINAL DIAGNOSTIC REPORT\\n\"\n",
    "    report_string += f\"     Record: {RECORD_TO_ANALYZE}\\n\"\n",
    "    report_string += \"=\"*50 + \"\\n\"\n",
    "    \n",
    "    # --- THIS IS THE FIX ---\n",
    "    # We will build the report string FIRST, and only save/print at the end.\n",
    "    \n",
    "    if total_beats is None or total_beats == 0:\n",
    "        report_string += \"Diagnosis: Inconclusive (No beats were detected or processed).\\n\"\n",
    "        report_string += \"This may be due to an error loading the model or the record.\"\n",
    "    \n",
    "    else:\n",
    "        # --- 1. Analyze the sequence for patterns ---\n",
    "        label_counts = Counter(all_predicted_labels)\n",
    "        v_tach_found = False\n",
    "        v_couplets = 0\n",
    "        s_tach_found = False\n",
    "        s_couplets = 0\n",
    "        consecutive_v_count = 0\n",
    "        consecutive_s_count = 0\n",
    "        \n",
    "        # We iterate through the *list* of predictions to find patterns\n",
    "        for label in all_predicted_labels:\n",
    "            # Check for Ventricular (V) patterns\n",
    "            if label == 2: # Class 'V'\n",
    "                consecutive_v_count += 1\n",
    "            else:\n",
    "                if consecutive_v_count == 2:\n",
    "                    v_couplets += 1\n",
    "                elif consecutive_v_count >= 3:\n",
    "                    v_tach_found = True\n",
    "                consecutive_v_count = 0 # Reset V counter\n",
    "\n",
    "            # Check for Supraventricular (S) patterns\n",
    "            if label == 1: # Class 'S'\n",
    "                consecutive_s_count += 1\n",
    "            else:\n",
    "                if consecutive_s_count == 2:\n",
    "                    s_couplets += 1\n",
    "                elif consecutive_s_count >= 3:\n",
    "                    s_tach_found = True\n",
    "                consecutive_s_count = 0 # Reset S counter\n",
    "        \n",
    "        # Check tail case (if the recording ends on a pattern)\n",
    "        if consecutive_v_count == 2:\n",
    "            v_couplets += 1\n",
    "        elif consecutive_v_count >= 3:\n",
    "            v_tach_found = True\n",
    "            \n",
    "        if consecutive_s_count == 2:\n",
    "            s_couplets += 1\n",
    "        elif consecutive_s_count >= 3:\n",
    "            s_tach_found = True\n",
    "\n",
    "        # --- 2. Get overall counts ---\n",
    "        count_n = label_counts.get(0, 0)\n",
    "        count_s = label_counts.get(1, 0) # Supraventricular\n",
    "        count_v = label_counts.get(2, 0) # Ventricular\n",
    "        count_f = label_counts.get(3, 0) # Fusion\n",
    "        total_arrhythmia_beats = count_s + count_v + count_f\n",
    "        percent_arrhythmia = (total_arrhythmia_beats / total_beats) * 100\n",
    "        percent_v = (count_v / total_beats) * 100\n",
    "        percent_s = (count_s / total_beats) * 100 # Added for S-burden\n",
    "\n",
    "        # --- 3. The \"Yes/No\" Detection (Smarter Rules) ---\n",
    "        # These thresholds are examples. A real clinical product\n",
    "        # would have these fine-tuned by a medical team.\n",
    "        \n",
    "        # We consider a \"significant burden\" to be > 5% of total beats\n",
    "        # for either S or V classes.\n",
    "        V_BURDEN_THRESHOLD = 5.0 \n",
    "        S_BURDEN_THRESHOLD = 5.0\n",
    "        \n",
    "        is_significant = False\n",
    "        if v_tach_found:\n",
    "            is_significant = True\n",
    "            report_string += \"Heart Disease Detection: YES (CRITICAL: Ventricular Tachycardia detected)\\n\"\n",
    "        elif s_tach_found:\n",
    "            is_significant = True\n",
    "            report_string += \"Heart Disease Detection: YES (SIGNIFICANT: Supraventricular Tachycardia detected)\\n\"\n",
    "        elif percent_v > V_BURDEN_THRESHOLD:\n",
    "             is_significant = True\n",
    "             report_string += f\"Heart Disease Detection: YES (Significant Ventricular Burden: {percent_v:.2f}%)\\n\"\n",
    "        elif percent_s > S_BURDEN_THRESHOLD:\n",
    "             is_significant = True\n",
    "             report_string += f\"Heart Disease Detection: YES (Significant Supraventricular Burden: {percent_s:.2f}%)\\n\"\n",
    "        elif total_arrhythmia_beats > 0:\n",
    "            report_string += \"Heart Disease Detection: NO (Benign/Occasional Arrhythmia Detected)\\n\"\n",
    "        else:\n",
    "            report_string += \"Heart Disease Detection: NO (Normal Sinus Rhythm Dominant)\\n\"\n",
    "            \n",
    "        # --- 4. The Diagnostic Summary (Smarter Report) ---\n",
    "        report_string += \"\\nDiagnostic Summary:\\n\"\n",
    "        \n",
    "        if total_arrhythmia_beats == 0:\n",
    "            report_string += f\"  - All {total_beats} detected beats were classified as Normal.\\n\"\n",
    "            report_string += \"  - No arrhythmias were detected in this recording.\\n\"\n",
    "        else:\n",
    "            # Report on Ventricular findings (most serious)\n",
    "            if v_tach_found:\n",
    "                report_string += \"  - !!! CRITICAL FINDING: Detected Ventricular Tachycardia (3+ 'V' beats in a row).\\n\"\n",
    "            elif v_couplets > 0:\n",
    "                report_string += f\"  - Detected {v_couplets} Ventricular Couplet(s) (2 'V' beats in a row).\\n\"\n",
    "            elif count_v > 0:\n",
    "                 report_string += f\"  - Detected {count_v} isolated Ventricular beat(s) (PVCs).\\n\"\n",
    "\n",
    "            # Report on Supraventricular findings\n",
    "            if s_tach_found:\n",
    "                report_string += f\"  - SIGNIFICANT FINDING: Detected Supraventricular Tachycardia (3+ 'S' beats in a row).\\n\"\n",
    "            elif s_couplets > 0:\n",
    "                report_string += f\"  - Detected {s_couplets} Supraventricular Couplet(s) (2 'S' beats in a row).\\n\"\n",
    "            elif count_s > 0:\n",
    "                report_string += f\"  - Detected {count_s} isolated Supraventricular beat(s) (APBs).\\n\"\n",
    "            \n",
    "            # Report on Fusion beats\n",
    "            if count_f > 0:\n",
    "                report_string += f\"  - Detected {count_f} Fusion beat(s).\\n\"\n",
    "            \n",
    "            # Add clinical context\n",
    "            if not is_significant and total_arrhythmia_beats > 0:\n",
    "                report_string += f\"\\n  - Clinical Note: Occasional arrhythmias were detected ({percent_arrhythmia:.2f}%), \\n\"\n",
    "                report_string += \"    but no dangerous patterns or significant burden (>5%) was found.\\n\"\n",
    "\n",
    "    report_string += \"\\n\" + \"=\"*50\n",
    "    \n",
    "    # Print the full diagnostic report\n",
    "    print(report_string, flush=True)\n",
    "\n",
    "    # Save the diagnostic report to its own file\n",
    "    report_filename = f\"diagnostic_report_{RECORD_TO_ANALYZE}.txt\"\n",
    "    try:\n",
    "        with open(report_filename, \"w\") as f:\n",
    "            f.write(report_string)\n",
    "        print(f\"\\nSUCCESS: Diagnostic report also saved to {report_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nWarning: Could not save diagnostic report file: {e}\")\n",
    "    \n",
    "    # Now we can safely return\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0f110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting 5-Step Pipeline for Record: 234 ---\n",
      "\n",
      "Step 1: Loading raw signal from C:\\Me\\College\\4th\\Ai_in_healthcare\\Ai_in_healthcare_project\\database\\234...\n",
      "Signal loaded successfully. Shape: (650000, 2), Fs: 360 Hz\n",
      "\n",
      "Step 2: Finding all heartbeats (QRS detection)...\n",
      "Found 2753 heartbeats (QRS peaks).\n",
      "\n",
      "Step 3: Extracting, filtering, and normalizing all segments...\n",
      "Created batch of 2753 valid segments.\n",
      "\n",
      "Step 4: Loading model and running batch prediction...\n",
      "Model 'optimal_ecg_model.keras' loaded.\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step\n",
      "Prediction complete. Got 2753 labels.\n",
      "\n",
      "Step 5: Generating final arrhythmia report...\n",
      "\n",
      "========================================\n",
      "     MODEL PREDICTION REPORT\n",
      "     Record: 234\n",
      "========================================\n",
      "Total Beats Detected (by gqrs_detect): 2753\n",
      "\n",
      "  N (Normal)               : 2698   beats (98.00%)\n",
      "  S (Supraventricular)     : 52     beats (1.89%)\n",
      "  V (Ventricular)          : 3      beats (0.11%)\n",
      "  F (Fusion)               : 0      beats (0.00%)\n",
      "  Q (Unclassifiable)       : 0      beats (0.00%)\n",
      "========================================\n",
      "\n",
      "SUCCESS: Full report also saved to final_report_234.txt\n",
      "Please open this file to see the untruncated output.\n",
      "\n",
      "========================================\n",
      "     GENERATING GROUND TRUTH REPORT\n",
      "     Record: 234\n",
      "========================================\n",
      "\n",
      "SUCCESS: Ground truth report saved to ground_truth_report_234.txt\n",
      "\n",
      "==================================================\n",
      "     FINAL DIAGNOSTIC REPORT\n",
      "     Record: 234\n",
      "==================================================\n",
      "Heart Disease Detection: YES (SIGNIFICANT: Supraventricular Tachycardia detected)\n",
      "\n",
      "Diagnostic Summary:\n",
      "  - Detected 3 isolated Ventricular beat(s) (PVCs).\n",
      "  - SIGNIFICANT FINDING: Detected Supraventricular Tachycardia (3+ 'S' beats in a row).\n",
      "\n",
      "==================================================\n",
      "\n",
      "SUCCESS: Diagnostic report also saved to diagnostic_report_234.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if np.array_equal(GLOBAL_MEAN, np.array([ 0.02254995, -0.00905314])) == False:\n",
    "         print(\"=\"*50)\n",
    "         print(\"ERROR: Please update GLOBAL_MEAN and GLOBAL_STD in this script!\")\n",
    "         print(\"Copy the values from Cell 5 of your 'dataset_access_FIXED.ipynb' notebook.\")\n",
    "         print(\"=\"*50)\n",
    "    else:\n",
    "        all_pred_labels, total_beats = analyze_full_record(RECORD_FILE)\n",
    "        check_ground_truth(RECORD_FILE)\n",
    "        generate_diagnostic_report(all_pred_labels, total_beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad41ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
